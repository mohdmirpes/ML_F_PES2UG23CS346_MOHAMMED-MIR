{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bixlHbSNBjix"
      },
      "source": [
        "# **Part A**\n",
        "Count / Frequency based Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jMQMMdXB75_2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# =======================================================\n",
        "# TODO: Students must implement the following steps:\n",
        "# 1. Complete the fit method in NaiveBayesClassifier (4 TODOs for log prior and log likelihood calculation).\n",
        "# 2. Complete the predict method in NaiveBayesClassifier (2 TODOs for log probability accumulation and final argmax).\n",
        "# 3. Complete the data loading calls in Section 2.\n",
        "# 4. Initialize CountVectorizer with proper parameters in Section 3a.\n",
        "# 5. Complete the feature transformation (fit_transform and transform) in Section 3a.\n",
        "# 6. Initialize and fit the custom nb_model in Section 3b.\n",
        "# 7. Use the fitted nb_model to generate predictions in Section 4.\n",
        "# =======================================================\n",
        "\n",
        "\n",
        "# Data loading function (DO NOT CHANGE)\n",
        "def load_pubmed_rct_file(filepath):\n",
        "    \"\"\"\n",
        "    Reads a .txt file from the PubMed 20k RCT dataset.\n",
        "    Returns a DataFrame with 'label' and 'sentence'.\n",
        "    \"\"\"\n",
        "    labels, sentences = [], []\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line or '\\t' not in line:\n",
        "                continue\n",
        "            label, sent = line.split('\\t', maxsplit=1)\n",
        "            labels.append(label)\n",
        "            sentences.append(sent)\n",
        "    return pd.DataFrame({'label': labels, 'sentence': sentences})\n",
        "\n",
        "\n",
        "# Implementing Multinomial Naive Bayes from scratch\n",
        "class NaiveBayesClassifier:\n",
        "    \"\"\"\n",
        "    Multinomial Naive Bayes Classifier implemented from scratch.\n",
        "    It is suitable for both Count and TF-IDF features.\n",
        "    \"\"\"\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "        self.class_priors = {}\n",
        "        self.feature_log_probs = {}\n",
        "        self.classes = None\n",
        "        self.vocabulary_size = 0\n",
        "\n",
        "    def fit(self, X_counts, y):\n",
        "        \"\"\"Fit the model using a document-term count matrix and labels.\"\"\"\n",
        "        y_array = y.to_numpy()\n",
        "        self.classes = np.unique(y_array)\n",
        "        self.vocabulary_size = X_counts.shape[1]\n",
        "\n",
        "        total_docs = X_counts.shape[0]\n",
        "\n",
        "        for c in self.classes:\n",
        "            X_c = X_counts[y_array == c]\n",
        "\n",
        "            # Calculate class prior with simple frequency (no smoothing required for priors)\n",
        "            n_c = X_c.shape[0]\n",
        "            self.class_priors[c] = np.log(n_c / total_docs) if total_docs > 0 else -np.inf\n",
        "\n",
        "            # Sum counts of each feature for class c (returns 1D array)\n",
        "            feature_sum = X_c.sum(axis=0).A1\n",
        "            total_mass = np.sum(feature_sum)\n",
        "\n",
        "            # Apply Laplace smoothing to get likelihoods P(w|C)\n",
        "            numerator = feature_sum + self.alpha\n",
        "            denominator = total_mass + self.alpha * self.vocabulary_size\n",
        "            # store log probabilities for numerical stability\n",
        "            self.feature_log_probs[c] = np.log(numerator / denominator)\n",
        "\n",
        "    def predict(self, X_counts):\n",
        "        \"\"\"Predict class labels for rows in X_counts (sparse matrix).\"\"\"\n",
        "        y_pred = []\n",
        "        for i in range(X_counts.shape[0]):\n",
        "            scores = {}\n",
        "\n",
        "            x_i = X_counts.getrow(i)\n",
        "\n",
        "            for c in self.classes:\n",
        "                # start with the log prior for the class\n",
        "                log_prob = float(self.class_priors[c])\n",
        "                log_likelihoods = self.feature_log_probs[c]\n",
        "\n",
        "                # Only iterate non-zero features for efficiency\n",
        "                non_zero_indices = x_i.indices\n",
        "                non_zero_data = x_i.data\n",
        "\n",
        "                if len(non_zero_indices) > 0:\n",
        "                    contrib = np.sum(non_zero_data * log_likelihoods[non_zero_indices])\n",
        "                    log_prob += float(contrib)\n",
        "\n",
        "                scores[c] = log_prob\n",
        "\n",
        "            # Choose the class with the maximum log-probability\n",
        "            predicted_class = max(scores, key=scores.get)\n",
        "            y_pred.append(predicted_class)\n",
        "\n",
        "        return np.array(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJlibd_d9U9X",
        "outputId": "5c6743bd-c77b-465a-f349-11a7bd6b480e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 180040\n",
            "Dev   samples: 30212\n",
            "Test  samples: 30135\n",
            "Classes: ['BACKGROUND', 'CONCLUSIONS', 'METHODS', 'OBJECTIVE', 'RESULTS']\n"
          ]
        }
      ],
      "source": [
        "# Load and Prepare Data (DO NOT CHANGE)\n",
        "dir_path = './'\n",
        "try:\n",
        "    train_df = load_pubmed_rct_file(os.path.join(dir_path, 'train.txt'))\n",
        "    dev_df   = load_pubmed_rct_file(os.path.join(dir_path, 'dev.txt'))\n",
        "    test_df  = load_pubmed_rct_file(os.path.join(dir_path, 'test.txt'))\n",
        "\n",
        "    print(f\"Train samples: {len(train_df)}\")\n",
        "    print(f\"Dev   samples: {len(dev_df)}\")\n",
        "    print(f\"Test  samples: {len(test_df)}\")\n",
        "\n",
        "    X_train, y_train = train_df['sentence'], train_df['label']\n",
        "    X_dev,   y_dev   = dev_df['sentence'],   dev_df['label']\n",
        "    X_test,  y_test  = test_df['sentence'],  test_df['label']\n",
        "    target_names = sorted(y_train.unique()) if len(y_train) > 0 else []\n",
        "    print(f\"Classes: {target_names}\")\n",
        "\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"Error: Dataset file not found. Please ensure the files are uploaded.\")\n",
        "    X_train, y_train = pd.Series([]), pd.Series([])\n",
        "    X_dev, y_dev = pd.Series([]), pd.Series([])\n",
        "    X_test, y_test = pd.Series([]), pd.Series([])\n",
        "    target_names = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zko4lfcC9k7g",
        "outputId": "0f47eb05-fb1f-4cc6-8341-297eecb9731d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting Count Vectorizer and transforming training data...\n",
            "Vocabulary size: 301234\n",
            "Transforming test data...\n",
            "\n",
            "Training the Custom Naive Bayes Classifier (from scratch)...\n",
            "Training complete.\n"
          ]
        }
      ],
      "source": [
        "# Feature Extraction and Custom Model Training\n",
        "if X_train is not None and len(X_train) > 0:\n",
        "\n",
        "    # Initialize and fit the CountVectorizer for count-based features\n",
        "    count_vectorizer = CountVectorizer(\n",
        "        lowercase=True,\n",
        "        strip_accents='unicode',\n",
        "        stop_words='english',\n",
        "        # Use unigrams and bigrams to capture short phrases\n",
        "        ngram_range=(1, 2),\n",
        "        # ignore extremely rare tokens\n",
        "        min_df=2\n",
        "    )\n",
        "\n",
        "    print(\"Fitting Count Vectorizer and transforming training data...\")\n",
        "    # Fit the vectorizer on X_train and transform\n",
        "    X_train_counts = count_vectorizer.fit_transform(X_train)\n",
        "    if X_train_counts is not None:\n",
        "        print(f\"Vocabulary size: {X_train_counts.shape[1]}\")\n",
        "\n",
        "    print(\"Transforming test data...\")\n",
        "    # Transform X_test using the fitted vectorizer\n",
        "    X_test_counts = count_vectorizer.transform(X_test)\n",
        "\n",
        "\n",
        "    # Train Custom Naive Bayes Classifier\n",
        "    print(\"\\nTraining the Custom Naive Bayes Classifier (from scratch)...\")\n",
        "\n",
        "    # Initialize the custom NaiveBayesClassifier\n",
        "    nb_model = NaiveBayesClassifier(alpha=1.0)\n",
        "\n",
        "    # Fit the model using X_train_counts and y_train\n",
        "    nb_model.fit(X_train_counts, y_train)\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "else:\n",
        "    print(\"Skipping feature extraction and training: Training data is empty or not loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ef-tgnFD9_86",
        "outputId": "682fe5d6-81c3-4ba9-db89-6ebd8b2c61da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Test Set Evaluation (Custom Count-Based Naive Bayes) ===\n",
            "Accuracy: 0.7571\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.57      0.56      0.57      3621\n",
            " CONCLUSIONS       0.63      0.69      0.66      4571\n",
            "     METHODS       0.81      0.89      0.85      9897\n",
            "   OBJECTIVE       0.60      0.43      0.50      2333\n",
            "     RESULTS       0.87      0.80      0.84      9713\n",
            "\n",
            "    accuracy                           0.76     30135\n",
            "   macro avg       0.70      0.68      0.68     30135\n",
            "weighted avg       0.76      0.76      0.75     30135\n",
            "\n",
            "Macro-averaged F1 score: 0.6825\n"
          ]
        }
      ],
      "source": [
        "# Predict and evaluate on test set\n",
        "print(\"\\n=== Test Set Evaluation (Custom Count-Based Naive Bayes) ===\")\n",
        "\n",
        "y_test_pred = None\n",
        "if 'nb_model' in locals() and 'X_test_counts' in locals() and X_test_counts is not None and X_test_counts.shape[0] > 0:\n",
        "    y_test_pred = nb_model.predict(X_test_counts)\n",
        "\n",
        "if y_test_pred is not None and len(y_test_pred) > 0:\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
        "    test_f1 = f1_score(y_test, y_test_pred, average='macro')\n",
        "    print(f\"Macro-averaged F1 score: {test_f1:.4f}\")\n",
        "else:\n",
        "    print(\"Prediction step failed or incomplete.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "CouhQ1RM-Z_C"
      },
      "outputs": [],
      "source": [
        "# Confusion Matrix on test set\n",
        "    # // TODO: Use the confusion_matrix, matplotlib, and seaborn libraries to generate\n",
        "    # a visual confusion matrix (heatmap) for the predicted results.\n",
        "    # if y_test_pred is not None:\n",
        "    #     cm = confusion_matrix(...)\n",
        "    #     plt.figure(...)\n",
        "    #     sns.heatmap(...)\n",
        "    #     plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVHIiaD7Bhna"
      },
      "source": [
        "# **Part B**\n",
        "TF-IDF score based Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbMuNX28BhPN",
        "outputId": "5c1a0e1e-a093-4363-f806-cfabe50a3af5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training initial Naive Bayes pipeline...\n",
            "Training complete.\n",
            "\n",
            "=== Test Set Evaluation (Initial Sklearn Model) ===\n",
            "Accuracy: 0.6996\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.61      0.37      0.46      3621\n",
            " CONCLUSIONS       0.61      0.55      0.57      4571\n",
            "     METHODS       0.68      0.88      0.77      9897\n",
            "   OBJECTIVE       0.72      0.09      0.16      2333\n",
            "     RESULTS       0.77      0.85      0.81      9713\n",
            "\n",
            "    accuracy                           0.70     30135\n",
            "   macro avg       0.68      0.55      0.56     30135\n",
            "weighted avg       0.69      0.70      0.67     30135\n",
            "\n",
            "Macro-averaged F1 score: 0.5555\n",
            "Grid search complete.\n",
            "Best params: {'nb__alpha': 0.5, 'tfidf__min_df': 5, 'tfidf__ngram_range': (1, 2)}\n",
            "Best CV score (f1_macro): 0.6069240726682121\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# =======================================================\n",
        "# Define a Pipeline named 'pipeline' using TfidfVectorizer and MultinomialNB.\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(lowercase=True, strip_accents='unicode', stop_words='english')),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Train the initial pipeline on the training set (if available)\n",
        "print(\"Training initial Naive Bayes pipeline...\")\n",
        "if 'X_train' in locals() and len(X_train) > 0:\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    print(\"Training complete.\")\n",
        "else:\n",
        "    print(\"Training skipped: training data not available.\")\n",
        "\n",
        "# Predict and evaluate on test set\n",
        "print(\"\\n=== Test Set Evaluation (Initial Sklearn Model) ===\")\n",
        "y_test_pred = None\n",
        "if 'pipeline' in locals() and 'X_test' in locals() and len(X_test) > 0:\n",
        "    try:\n",
        "        y_test_pred = pipeline.predict(X_test)\n",
        "    except Exception as e:\n",
        "        print(\"Prediction failed:\", e)\n",
        "\n",
        "if y_test_pred is not None and len(y_test_pred) > 0:\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")\n",
        "    print(classification_report(y_test, y_test_pred, target_names=target_names))\n",
        "    print(f\"Macro-averaged F1 score: {f1_score(y_test, y_test_pred, average='macro'):.4f}\")\n",
        "else:\n",
        "    print(\"Initial model evaluation skipped: Predictions not available.\")\n",
        "\n",
        "# Hyperparameter Tuning using GridSearchCV\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
        "    'tfidf__min_df': [1, 2, 5],\n",
        "    'nb__alpha': [0.5, 1.0, 2.0],\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV using the pipeline and param_grid. Ensure cv=3 and scoring='f1_macro' are used.\n",
        "grid = None\n",
        "if 'X_dev' in locals() and len(X_dev) > 0:\n",
        "    grid = GridSearchCV(pipeline, param_grid, cv=3, scoring='f1_macro', n_jobs=-1)\n",
        "    grid.fit(X_dev, y_dev)\n",
        "    print(\"Grid search complete.\")\n",
        "    print(\"Best params:\", grid.best_params_)\n",
        "    print(\"Best CV score (f1_macro):\", grid.best_score_)\n",
        "else:\n",
        "    print(\"Hyperparameter tuning skipped: dev data not available.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXeRmXWvGq3I"
      },
      "source": [
        "# **Part C**\n",
        "Bayes Optimal Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ancOdkSFGqYp",
        "outputId": "e3ecbb94-4401-468e-bc11-3f6a1ecc8011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your full SRN (e.g., PES2UG23CS346): PES2UG23CS346\n",
            "My SRN isPES2UG23CS346\n",
            "Using dynamic sample size: 10346\n",
            "Actual sampled training set size used: 10346\n",
            "Using 10346 samples for training base models.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# =======================================================\n",
        "# TODO: Implement the following steps:\n",
        "# 1. Define the five diverse hypothesis pipelines (H1 to H5) using TfidfVectorizer\n",
        "#    and the specified classifiers (NB, LR, RF, DT, KNN).\n",
        "# 2. Train each of the five hypotheses on the sampled training data.\n",
        "# 3. Create a list of estimators for the VotingClassifier.\n",
        "# 4. Initialize and fit the VotingClassifier (Bayes Optimal Classifier approximation).\n",
        "# 5. Make final predictions and evaluate the BOC performance on the test data.\n",
        "# =======================================================\n",
        "\n",
        "# Sampling for faster training of multiple models (DO NOT CHANGE)\n",
        "#\n",
        "# *** STUDENT ACTION REQUIRED ***\n",
        "# This section dynamically calculates the sample size based on the student's SRN.\n",
        "# When running this cell, a prompt will appear asking for the full SRN.\n",
        "#\n",
        "BASE_SAMPLE_SIZE = 10000\n",
        "\n",
        "FULL_SRN = input(\"Please enter your full SRN (e.g., PES2UG23CS346): \")\n",
        "\n",
        "try:\n",
        "    if len(FULL_SRN) >= 3:\n",
        "        print(\"My SRN is\" + FULL_SRN)\n",
        "        srn_suffix_str = FULL_SRN[-3:]\n",
        "        srn_value = int(srn_suffix_str)\n",
        "    else:\n",
        "        raise ValueError(\"SRN too short.\")\n",
        "except (ValueError, IndexError):\n",
        "    print(\"WARNING: SRN input failed or format is incorrect. Using 10000.\")\n",
        "    srn_value = 0\n",
        "\n",
        "SAMPLE_SIZE = BASE_SAMPLE_SIZE + srn_value\n",
        "\n",
        "print(f\"Using dynamic sample size: {SAMPLE_SIZE}\")\n",
        "\n",
        "# Assuming X_train and y_train were loaded in Part A\n",
        "# Placeholder initialization in case data wasn't loaded in the environment\n",
        "if 'X_train' not in locals() or len(X_train) == 0:\n",
        "    print(\"Warning: Training data not found. Using small placeholder data.\")\n",
        "    X_train = pd.Series([\"sample text one\", \"sample text two\", \"sample text three\"])\n",
        "    y_train = pd.Series([\"BACKGROUND\", \"METHODS\", \"RESULTS\"])\n",
        "    X_test = pd.Series([\"test text one\", \"test text two\"])\n",
        "    y_test = pd.Series([\"BACKGROUND\", \"METHODS\"])\n",
        "    target_names = [\"BACKGROUND\", \"CONCLUSIONS\", \"METHODS\", \"OBJECTIVE\", \"RESULTS\"]\n",
        "\n",
        "# Create the sampled training subset\n",
        "# Ensure SAMPLE_SIZE does not exceed the size of the actual training data\n",
        "effective_sample_size = min(SAMPLE_SIZE, len(X_train))\n",
        "X_train_sampled = X_train[:effective_sample_size]\n",
        "y_train_sampled = y_train[:effective_sample_size]\n",
        "print(f\"Actual sampled training set size used: {effective_sample_size}\")\n",
        "\n",
        "X_train_sampled = X_train[:SAMPLE_SIZE]\n",
        "y_train_sampled = y_train[:SAMPLE_SIZE]\n",
        "print(f\"Using {len(X_train_sampled)} samples for training base models.\")\n",
        "\n",
        "# Base TF-IDF parameters (DO NOT CHANGE)\n",
        "tfidf_params = {\n",
        "    'lowercase': True,\n",
        "    'strip_accents': 'unicode',\n",
        "    'stop_words': 'english',\n",
        "    'ngram_range': (1, 1),\n",
        "    'min_df': 5\n",
        "}\n",
        "\n",
        "# Define the five diverse hypotheses/pipelines\n",
        "\n",
        "# Multinomial Naive Bayes\n",
        "h1_nb = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "                  ('clf', MultinomialNB(alpha=1.0, fit_prior=False))])\n",
        "\n",
        "# Logistic Regression\n",
        "h2_lr = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "                  ('clf', LogisticRegression(solver='liblinear', multi_class='auto', max_iter=1000, random_state=42))])\n",
        "\n",
        "# Random Forest Classifier\n",
        "h3_rf = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "                  ('clf', RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1))])\n",
        "\n",
        "# Decision Tree Classifier\n",
        "h4_dt = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "                  ('clf', DecisionTreeClassifier(max_depth=10, random_state=42))])\n",
        "\n",
        "# K-Nearest Neighbors\n",
        "h5_knn = Pipeline([('tfidf', TfidfVectorizer(**tfidf_params)),\n",
        "                  ('clf', KNeighborsClassifier(n_neighbors=5, n_jobs=-1))])\n",
        "\n",
        "hypotheses = [h1_nb, h2_lr, h3_rf, h4_dt, h5_knn]\n",
        "hypothesis_names = ['NaiveBayes', 'LogisticRegression', 'RandomForest', 'DecisionTree', 'KNN']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk4kdlEpI3vN",
        "outputId": "e9be6a4d-86a3-4813-c5f7-f0366155cdc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training NaiveBayes...\n",
            "NaiveBayes trained.\n",
            "Training LogisticRegression...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LogisticRegression trained.\n",
            "Training RandomForest...\n",
            "RandomForest trained.\n",
            "Training DecisionTree...\n",
            "DecisionTree trained.\n",
            "Training KNN...\n",
            "KNN trained.\n",
            "All base models trained (or attempted).\n"
          ]
        }
      ],
      "source": [
        "# Train all five hypotheses on X_train_sampled and y_train_sampled using a for loop\n",
        "trained_hypotheses = []\n",
        "for name, est in zip(hypothesis_names, hypotheses):\n",
        "    try:\n",
        "        print(f\"Training {name}...\")\n",
        "        est.fit(X_train_sampled, y_train_sampled)\n",
        "        trained_hypotheses.append(est)\n",
        "        print(f\"{name} trained.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to train {name}: {e}\")\n",
        "\n",
        "print(\"All base models trained (or attempted).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E72idDSMI8GD",
        "outputId": "865ba22d-f089-439e-ea66-02495d074650"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting the VotingClassifier (BOC approximation)...\n",
            "VotingClassifier fitted.\n"
          ]
        }
      ],
      "source": [
        "# Implement and Evaluate the Bayes Optimal Classifier\n",
        "\n",
        "# List of (name, estimator) tuples for the VotingClassifier\n",
        "# Use the trained hypotheses when available\n",
        "estimators = list(zip(hypothesis_names, hypotheses))\n",
        "\n",
        "# Hard Voting (Majority Rule) for BOC approximation\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "boc_hard_voter = VotingClassifier(estimators=estimators, voting='hard', n_jobs=-1)\n",
        "\n",
        "print(\"\\nFitting the VotingClassifier (BOC approximation)...\")\n",
        "try:\n",
        "    boc_hard_voter.fit(X_train_sampled, y_train_sampled)\n",
        "    print(\"VotingClassifier fitted.\")\n",
        "except Exception as e:\n",
        "    print(\"VotingClassifier training failed:\", e)\n",
        "\n",
        "# Make the final BOC prediction on the test set\n",
        "y_boc_pred = None\n",
        "if 'boc_hard_voter' in locals() and hasattr(boc_hard_voter, 'predict') and len(X_test) > 0:\n",
        "    try:\n",
        "        y_boc_pred = boc_hard_voter.predict(X_test)\n",
        "    except Exception as e:\n",
        "        print(\"BOC prediction failed:\", e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pnCEdCxKiVZ",
        "outputId": "33f39ca7-8311-476e-8c1e-ebb86b3d83f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Final Evaluation: Bayes Optimal Classifier (Hard Voting) ===\n",
            "BOC Accuracy: 0.6527\n",
            "BOC Macro F1 Score: 0.5086\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  BACKGROUND       0.52      0.42      0.47      3621\n",
            " CONCLUSIONS       0.64      0.50      0.56      4571\n",
            "     METHODS       0.58      0.94      0.72      9897\n",
            "   OBJECTIVE       0.64      0.02      0.04      2333\n",
            "     RESULTS       0.86      0.67      0.76      9713\n",
            "\n",
            "    accuracy                           0.65     30135\n",
            "   macro avg       0.65      0.51      0.51     30135\n",
            "weighted avg       0.68      0.65      0.62     30135\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the Bayes Optimal Classifier (BOC)\n",
        "print(\"\\n=== Final Evaluation: Bayes Optimal Classifier (Hard Voting) ===\")\n",
        "\n",
        "if y_boc_pred is not None and len(y_boc_pred) > 0:\n",
        "    boc_accuracy = accuracy_score(y_test, y_boc_pred)\n",
        "    boc_f1 = f1_score(y_test, y_boc_pred, average='macro')\n",
        "    print(f\"BOC Accuracy: {boc_accuracy:.4f}\")\n",
        "    print(f\"BOC Macro F1 Score: {boc_f1:.4f}\")\n",
        "    print(classification_report(y_test, y_boc_pred, target_names=target_names))\n",
        "else:\n",
        "    print(\"BOC evaluation skipped: No predictions available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "R4hHv6BoKkPo"
      },
      "outputs": [],
      "source": [
        "# // TODO: Generate and visualize the Confusion Matrix (heatmap) for the BOC predictions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
